{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4bbd5e7-bbf4-482c-8db5-72851adaaf6d",
   "metadata": {},
   "source": [
    "# Pulze.ai API Tutorial\n",
    "\n",
    "This tutorial guides you through the process of interacting with the Pulze.ai API using the `openai` Python library. You will learn how to set up API requests, customize response preferences, and utilize custom prompts.\n",
    "\n",
    "## Installation\n",
    "\n",
    "Begin by installing the necessary Python package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de9fd491-f66b-4054-9fbc-cfcd56c6ce88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai==1.3.7\n",
      "  Downloading openai-1.3.7-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting anyio<4,>=3.5.0 (from openai==1.3.7)\n",
      "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai==1.3.7)\n",
      "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from openai==1.3.7)\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from openai==1.3.7)\n",
      "  Downloading pydantic-2.5.2-py3-none-any.whl.metadata (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai==1.3.7) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai==1.3.7) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /opt/conda/lib/python3.11/site-packages (from openai==1.3.7) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai==1.3.7) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai==1.3.7) (2023.7.22)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai==1.3.7)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai==1.3.7)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1.9.0->openai==1.3.7)\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pydantic-core==2.14.5 (from pydantic<3,>=1.9.0->openai==1.3.7)\n",
      "  Downloading pydantic_core-2.14.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.5 kB)\n",
      "Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m221.4/221.4 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.5.2-py3-none-any.whl (381 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m381.9/381.9 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.14.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: pydantic-core, h11, distro, anyio, annotated-types, pydantic, httpcore, httpx, openai\n",
      "  Attempting uninstall: anyio\n",
      "    Found existing installation: anyio 4.0.0\n",
      "    Uninstalling anyio-4.0.0:\n",
      "      Successfully uninstalled anyio-4.0.0\n",
      "Successfully installed annotated-types-0.6.0 anyio-3.7.1 distro-1.8.0 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 openai-1.3.7 pydantic-2.5.2 pydantic-core-2.14.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openai==1.3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c51f5f-259d-4692-9786-9019ac36737b",
   "metadata": {},
   "source": [
    "# Basic Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d7edb-0cbb-4f23-9b5f-421ef0194989",
   "metadata": {},
   "source": [
    "## Creating an App and Configuring the API Client\n",
    "\n",
    "- Create an example app at Pulze [Platform](https://platform.pulze.ai).\n",
    "- Retrieve your API Key from [https://platform.pulze.ai](https://platform.pulze.ai)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3a209d7-a61f-44b4-906e-d0d3799bb93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c87cf80b-8cc2-472b-ae52-dc70527caa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Pulze API Key:  ········\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "openai.api_key = getpass('Enter your Pulze API Key: ') # Availabe when creating a new app within the Pulze platform\n",
    "openai.base_url = \"https://api.pulze.ai/v1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f1dd9e-8ee7-4359-b3df-97f5d431cd01",
   "metadata": {},
   "source": [
    "# Customizing Requests\n",
    "\n",
    "## Setting Custom Labels and Weights\n",
    "\n",
    "Configure your request preferences in terms of cost, quality, and latency. In the first example, we prefer quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83219dc7-ccc9-4cf5-8dc6-b144f7f74168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer by openai/text-davinci-003 with total costs of 0.000740$ 0.412s:\n",
      "\n",
      "[COMPUTER]:\n",
      "That's an easy one - the answer is\n"
     ]
    }
   ],
   "source": [
    "# Set up your custom labels and weights\n",
    "labels = {\"foo\": \"bar\", \"group\": \"standard\"}\n",
    "weights = {\"cost\": 0, \"quality\": 1, \"latency\": 0}\n",
    "\n",
    "headers = {\n",
    "    \"Pulze-Labels\": json.dumps(labels),\n",
    "    \"Pulze-Weights\": json.dumps(weights),\n",
    "}\n",
    "\n",
    "openai.default_headers = headers\n",
    "\n",
    "chat_response = openai.chat.completions.create(\n",
    "    model=\"pulze-v0\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"I am bad at math, what is 1+1?\"}],\n",
    ")\n",
    "\n",
    "# Assuming chat_response has properties like 'model', 'metadata', etc.\n",
    "# and metadata has properties like 'costs' and 'latency'\n",
    "# and costs has a property 'total_tokens'\n",
    "print(\n",
    "    f\"Answer by {chat_response.model} with total costs of {chat_response.metadata['costs']['total_tokens']:.6f}$ {chat_response.metadata['latency']}s:\\n\"\n",
    ")\n",
    "print(chat_response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c06e239-6f03-4009-9da1-d8cea0d5b8cf",
   "metadata": {},
   "source": [
    "## Interpreting the Response\n",
    "\n",
    "Extract relevant information from the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d804453f-d1a4-4cd8-9b55-49d13afc4186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####### Raw Response #######\n",
      "ChatCompletion(id='2315fc76-3479-4565-a120-4254aebe89e6', choices=[Choice(finish_reason=None, index=0, message=ChatCompletionMessage(content='[CHATBOT]:\\nThe answer is 2.', role='assistant', function_call=None, tool_calls=None))], created=1701483003546, model='openai/text-davinci-003', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=12, prompt_tokens=21, total_tokens=33), metadata={'app_id': '92bca216-e64c-4bcb-a70a-e2359a6df125', 'model': {'model': 'text-davinci-003', 'provider': 'openai', 'namespace': 'openai/text-davinci-003'}, 'costs': {'total_tokens': 0.00066, 'prompt_tokens': 0.00042, 'completion_tokens': 0.00024}, 'cost_savings': {'total_tokens': 0.00132, 'prompt_tokens': 0.00084, 'completion_tokens': 0.00048}, 'latency': 0.601, 'category': 'Arts & Crafts', 'labels': {'foo': 'bar', 'group': 'standard', 'weights_cost': '0.0', 'weights_latency': '0.0', 'weights_quality': '1.0'}, 'scores': {'best_models': [{'openai/text-davinci-003': 1.0}, {'openai/gpt-3.5-turbo': 0.998}, {'openai/gpt-4': 0.997}, {'anthropic/claude-2': 0.996}, {'anthropic/claude-instant-v1': 0.989}]}, 'score': 1.0, 'temperature': 1.0, 'status_code': 200})\n",
      "#################################\n"
     ]
    }
   ],
   "source": [
    "print(\"####### Raw Response #######\")\n",
    "print(chat_response)\n",
    "print(\"#################################\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25b29e7-ef46-480b-9efd-17fa175fa08c",
   "metadata": {},
   "source": [
    "Let's change now the weights to just preference costs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69cef990-7a45-40ad-afa7-896cb1a0755e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer by mosaicml/mpt-7b-instruct with total costs of 0.000002$ 0.699s:\n",
      "\n",
      "----\n",
      "\n",
      "1: It’s two!\n"
     ]
    }
   ],
   "source": [
    "# Set up your custom labels and weights\n",
    "labels = {\"foo\": \"bar\", \"group\": \"standard\"}\n",
    "weights = {\"cost\": 1, \"quality\": 0, \"latency\": 0}\n",
    "\n",
    "headers = {\n",
    "    \"Pulze-Labels\": json.dumps(labels),\n",
    "    \"Pulze-Weights\": json.dumps(weights),\n",
    "}\n",
    "\n",
    "openai.default_headers = headers\n",
    "\n",
    "chat_response = openai.chat.completions.create(\n",
    "    model=\"pulze-v0\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"I am bad at math, what is 1+1?\"}],\n",
    ")\n",
    "\n",
    "# Assuming chat_response has properties like 'model', 'metadata', etc.\n",
    "# and metadata has properties like 'costs' and 'latency'\n",
    "# and costs has a property 'total_tokens'\n",
    "print(\n",
    "    f\"Answer by {chat_response.model} with total costs of {chat_response.metadata['costs']['total_tokens']:.6f}$ {chat_response.metadata['latency']}s:\\n\"\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c945ce-fe6c-421b-b25d-090094e33b31",
   "metadata": {},
   "source": [
    "Now, find the model that is having good quality but to the best price for this particular prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1242e44b-5e90-4c2a-877e-25f496ec108d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer by openai/gpt-3.5-turbo with total costs of 0.000042$ 0.768s:\n",
      "\n",
      "The sum of 1+1 is 2.\n"
     ]
    }
   ],
   "source": [
    "# Set up your custom labels and weights\n",
    "labels = {\"foo\": \"bar\", \"group\": \"standard\"}\n",
    "weights = {\"cost\": 0.5, \"quality\": 0.5, \"latency\": 0}\n",
    "\n",
    "headers = {\n",
    "    \"Pulze-Labels\": json.dumps(labels),\n",
    "    \"Pulze-Weights\": json.dumps(weights),\n",
    "}\n",
    "\n",
    "openai.default_headers = headers\n",
    "\n",
    "chat_response = openai.chat.completions.create(\n",
    "    model=\"pulze-v0\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"I am bad at math, what is 1+1?\"}],\n",
    ")\n",
    "\n",
    "# Assuming chat_response has properties like 'model', 'metadata', etc.\n",
    "# and metadata has properties like 'costs' and 'latency'\n",
    "# and costs has a property 'total_tokens'\n",
    "print(\n",
    "    f\"Answer by {chat_response.model} with total costs of {chat_response.metadata['costs']['total_tokens']:.6f}$ {chat_response.metadata['latency']}s:\\n\"\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30ae19f-e2f5-4648-ae7f-6d65c56685be",
   "metadata": {},
   "source": [
    "Let's just focus on latency and provide me with the fastest response. This takes the model that is having the last seen latency that is lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e18bf8-c025-4ae5-b1fd-d7bb8677bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer by openai/text-davinci-003 with total costs of 0.000640$ 0.621s:\n",
      "\n",
      "[BOT]:\n",
      "The answer is 2.\n"
     ]
    }
   ],
   "source": [
    "# Set up your custom labels and weights\n",
    "labels = {\"foo\": \"bar\", \"group\": \"standard\"}\n",
    "weights = {\"cost\": 0, \"quality\": 0, \"latency\": 1}\n",
    "\n",
    "headers = {\n",
    "    \"Pulze-Labels\": json.dumps(labels),\n",
    "    \"Pulze-Weights\": json.dumps(weights),\n",
    "}\n",
    "\n",
    "openai.default_headers = headers\n",
    "\n",
    "chat_response = openai.chat.completions.create(\n",
    "    model=\"pulze-v0\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"I am bad at math, what is 1+1?\"}],\n",
    ")\n",
    "\n",
    "# Assuming chat_response has properties like 'model', 'metadata', etc.\n",
    "# and metadata has properties like 'costs' and 'latency'\n",
    "# and costs has a property 'total_tokens'\n",
    "print(\n",
    "    f\"Answer by {chat_response.model} with total costs of {chat_response.metadata['costs']['total_tokens']:.6f}$ {chat_response.metadata['latency']}s:\\n\"\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55605909-a690-47d4-b1f6-2bd200354f9a",
   "metadata": {},
   "source": [
    "Clearly that answer is not of high quality but with `0.64s` the fastest response."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a190e-b7f7-4cff-ac9f-c2f1ad32af86",
   "metadata": {},
   "source": [
    "Now lets go to the [prompt section](https://platform.pulze.ai/prompts) and create a prompt to always respond like Santa Claus:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b511cfce-3406-4102-8da6-fe5337620d8a",
   "metadata": {},
   "source": [
    "```\n",
    "Respond like Santa Claus to the following, never break character: {{prompt}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1755839-4b5e-43b2-a280-ceaf145f412d",
   "metadata": {},
   "source": [
    "Save the prompt id to your clipboard and add it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "58ed8c15-a041-4d60-b7f2-2b1e355a29bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your Prompt ID:  ········\n"
     ]
    }
   ],
   "source": [
    "prompt_id = getpass('Enter your Prompt ID: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f98a4a-05a3-4719-9050-10705bc574b2",
   "metadata": {},
   "source": [
    "Now let's showcase how we can do a request using that prompt with the same app. See also https://docs.pulze.ai/features/custom-headers/policies#prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9b9520b-4693-43ae-8014-257f76f378a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer by anthropic/claude-v1 with total costs of 0.000645$ 1.003s:\n",
      "\n",
      "Ho ho ho! I'm Santa Claus, of course! Jolly old\n"
     ]
    }
   ],
   "source": [
    "# Set up your custom labels and weights\n",
    "labels = {\"group\": \"standard\"}\n",
    "weights = {\"cost\": 0, \"quality\": 1, \"latency\": 0}\n",
    "policies = {\"prompt_id\": prompt_id}\n",
    "\n",
    "headers = {\n",
    "    \"Pulze-Labels\": json.dumps(labels),\n",
    "    \"Pulze-Weights\": json.dumps(weights),\n",
    "    \"Pulze-Policies\": json.dumps(policies),\n",
    "}\n",
    "\n",
    "openai.default_headers = headers\n",
    "\n",
    "chat_response = openai.chat.completions.create(\n",
    "    model=\"pulze-v0\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Who are you?\"}],\n",
    ")\n",
    "\n",
    "# Assuming chat_response has properties like 'model', 'metadata', etc.\n",
    "# and metadata has properties like 'costs' and 'latency'\n",
    "# and costs has a property 'total_tokens'\n",
    "print(\n",
    "    f\"Answer by {chat_response.model} with total costs of {chat_response.metadata['costs']['total_tokens']:.6f}$ {chat_response.metadata['latency']}s:\\n\"\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc1dba-ccd2-4f21-b2f3-52a7718bc011",
   "metadata": {},
   "source": [
    "# Function Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16768f93-e43e-4a2c-831a-0b411519c1dd",
   "metadata": {},
   "source": [
    "`Function Calling` can be achieved by having our `pulze` model automatically identify that you are doing function calling and routing you to the best model based on your prompt and function.  Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4c8d96f-618a-47bb-a8ac-9f4ff5964e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer by openai/gpt-3.5-turbo with total costs of 0.000094$ 0.663s:\n",
      "\n",
      "ChatCompletionMessage(content='', role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_XZMlM3zEYuhDX6ixWO76RIBb', function=Function(arguments='{\\n  \"a\": 1,\\n  \"b\": 1\\n}', name='sum_numbers'), type=None)]) \n",
      "\n",
      "Function sum_numbers with {'a': 1, 'b': 1} Response: {\"result\": 2}\n"
     ]
    }
   ],
   "source": [
    "# Set up your custom labels and weights\n",
    "labels = {\"group\": \"function_call\"}\n",
    "weights = {\"cost\": 0, \"quality\": 1, \"latency\": 0}\n",
    "\n",
    "headers = {\n",
    "    \"Pulze-Labels\": json.dumps(labels),\n",
    "    \"Pulze-Weights\": json.dumps(weights),\n",
    "}\n",
    "\n",
    "# Dummy functions for demonstration\n",
    "def sum_numbers(a, b):\n",
    "    \"\"\"Sum two numbers.\"\"\"\n",
    "    return json.dumps({\"result\": a + b})\n",
    "\n",
    "# Define the available functions as tools\n",
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"sum_numbers\",\n",
    "            \"description\": \"Sum two numbers\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\"a\": {\"type\": \"number\"}, \"b\": {\"type\": \"number\"}},\n",
    "                \"required\": [\"a\", \"b\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n",
    "\n",
    "openai.default_headers = headers\n",
    "\n",
    "chat_response = openai.chat.completions.create(\n",
    "    model=\"pulze-v0\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Can you sum 1 with 1?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice={\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\"name\": \"sum_numbers\"},\n",
    "    },  # force save_ratings\n",
    ")\n",
    "\n",
    "# Assuming chat_response has properties like 'model', 'metadata', etc.\n",
    "# and metadata has properties like 'costs' and 'latency'\n",
    "# and costs has a property 'total_tokens'\n",
    "print(\n",
    "    f\"Answer by {chat_response.model} with total costs of {chat_response.metadata['costs']['total_tokens']:.6f}$ {chat_response.metadata['latency']}s:\\n\"\n",
    ")\n",
    "\n",
    "print(chat_response.choices[0].message, \"\\n\")\n",
    "\n",
    "tool_calls = chat_response.choices[0].message.tool_calls\n",
    "# Check if the model wanted to call a function\n",
    "if tool_calls:\n",
    "    # Mapping of available functions\n",
    "    available_functions = {\"sum_numbers\": sum_numbers}\n",
    "\n",
    "    # Process each function call\n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(tool_call.function.arguments)\n",
    "\n",
    "        # Call the function and get the response\n",
    "        function_response = function_to_call(**function_args)\n",
    "\n",
    "        print(\n",
    "            f\"Function {function_name} with {function_args} Response: {function_response}\",\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7895d4a7-98dc-4afb-9051-ad50add677d3",
   "metadata": {},
   "source": [
    "# Targeting a specific Model\n",
    "\n",
    "We also allow you to target specific models. You could either do this through the UI by just selecting e.g. a single model or you do it programatically with every request.\n",
    "\n",
    "This is possible because we introduced the `Fully Qualified Model Path` that let's you target a specific model e.g. like `anthropic/claude-2.0` or `openai/gpt-4`.\n",
    "\n",
    "Keep in mind you can just target a model that is also enabled as model in your application. Alternatively, If you would target our `pulze` model, we would choose from the enabled models the best one. Here is an example how if you don't like the `openai/gpt-3.5-turbo` performance, you very easily can switch to `gpt-4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d36e6d4c-793d-45bb-91ce-11841fb504e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer by openai/gpt-4 with total costs of 0.002820$ 1.042s:\n",
      "\n",
      "Function sum_numbers with {'a': 1, 'b': 1} Response: {\"result\": 2}\n"
     ]
    }
   ],
   "source": [
    "chat_response = openai.chat.completions.create(\n",
    "    model=\"openai/gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Can you sum 1 with 1?\"}],\n",
    "    tools=tools,\n",
    "    tool_choice={\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\"name\": \"sum_numbers\"},\n",
    "    },  # force save_ratings\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"Answer by {chat_response.model} with total costs of {chat_response.metadata['costs']['total_tokens']:.6f}$ {chat_response.metadata['latency']}s:\\n\"\n",
    ")\n",
    "print(\n",
    "    f\"Function {function_name} with {function_args} Response: {function_response}\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
